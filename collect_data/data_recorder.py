import h5py
import os
from datetime import datetime
from collections import defaultdict
import numpy as np
import time


from franka_robot import FrankaRobot, RobotInputs
from cameras import Cameras


class DataRecorder:
    def __init__(self, robot: FrankaRobot, cameras: Cameras):
        self.robot = robot
        self.cameras = cameras
        self.data_dict = defaultdict(list)
        self.dataset_dir = "data"
        self.camera_names = ["ext1", "ext2", "wrist"]
        self.start_time = None

    def reset(self):
        self.data_dict = defaultdict(list)
        self.start_time = time.time()

    def record_sample(self, robot_inputs: RobotInputs, dt):
        start_rec = time.time()

        action = [robot_inputs.left_x, robot_inputs.left_y, robot_inputs.right_z,
                  robot_inputs.roll, robot_inputs.pitch, robot_inputs.yaw, robot_inputs.gripper]
        self.data_dict["/observations/qpos"].append(
            self.robot.robot.current_joint_positions)
        self.data_dict["/observations/qvel"].append(
            self.robot.robot.current_joint_velocities)

        self.data_dict["/observations/gpos"].append(
            np.array([self.robot.gripper.width]))

        rotq = self.robot.robot.current_cartesian_state.pose.end_effector_pose.quaternion
        rotrpy = self.robot.quaternion_array_to_rpy(rotq)
        self.data_dict["/observations/ee_pos_q"].append(
            rotq)
        self.data_dict["/observations/ee_pos_rpy"].append(
            rotrpy)
        self.data_dict["/observations/ee_pos_t"].append(
            self.robot.robot.current_cartesian_state.pose.end_effector_pose.translation)
        self.data_dict["/observations/ee_twist_ang"].append(
            self.robot.robot.current_cartesian_velocity.end_effector_twist.angular)
        self.data_dict["/observations/ee_twist_lin"].append(
            self.robot.robot.current_cartesian_velocity.end_effector_twist.linear)

        self.data_dict["/observations/elbow_jnt3_pos"].append(
            np.array([self.robot.robot.current_cartesian_state.pose.elbow_state.joint_3_pos]))
        self.data_dict["/observations/elbow_jnt4_flip"].append(
            np.array([self.robot.robot.current_cartesian_state.pose.elbow_state.joint_4_flip.value]))

        #   /**
        #    * \f$^OF_{K,\text{ext}}\f$
        #    * Estimated external wrench (force, torque) acting on stiffness frame,
        #    * expressed relative to the @ref o-frame "base frame". Forces applied by the
        #    * robot to the environment are positive, while forces applied by the
        #    * environment on the robot are negative. Becomes
        #    * \f$[0,0,0,0,0,0]\f$ when near or in a singularity. See also @ref k-frame
        #    * "Stiffness frame K". Unit: \f$[N,N,N,Nm,Nm,Nm]\f$.
        #    */
        robot_state = self.robot.robot.state
        self.data_dict["/observations/O_F_ext_hat_K"].append(
            robot_state.O_F_ext_hat_K)

        #   /**
        #    * \f$\tau_{J}\f$
        #    * Measured link-side joint torque sensor signals. Unit: \f$[Nm]\f$
        #    */
        #   Vector7d tau_J{};  // NOLINT(readability-identifier-naming)
        self.data_dict["/observations/tau_J"].append(
            robot_state.tau_J)

        #   /**
        #    * \f$\dot{\tau_{J}}\f$
        #    * Derivative of measured link-side joint torque sensor signals. Unit:
        #    * \f$[\frac{Nm}{s}]\f$
        #    */
        self.data_dict["/observations/dtau_J"].append(
            robot_state.dtau_J)

        #   /**
        #    * \f$\hat{\tau}_{\text{ext}}\f$
        #    * Low-pass filtered torques generated by external forces on the joints. It
        #    * does not include configured end-effector and load nor the mass and dynamics
        #    * of the robot. tau_ext_hat_filtered is the error between tau_J and the
        #    * expected torques given by the robot model. Unit: \f$[Nm]\f$.
        #    */
        self.data_dict["/observations/tau_ext_hat_filtered"].append(
            robot_state.tau_ext_hat_filtered)

        self.data_dict["/action"].append(action)
        self.data_dict["/tm"].append(np.array([dt]))

        start = time.time()
        frames = self.cameras.get_frames()
        # print(f"color {time.time() - start}")

        self.data_dict["/observations/images/wrist"].append(frames["wrist"])
        self.data_dict["/observations/images/ext1"].append(frames["ext1"])
        self.data_dict["/observations/images/ext2"].append(frames["ext2"])

        # start = time.time()
        # depth_frames = self.cameras.get_depth_frames()
        # print(f"depth {time.time() - start}")
        # # Store depth frames, webcams don't have depth
        # for cam_name in self.camera_names:
        #     if depth_frames[cam_name] is not None:
        #         self.data_dict[f"/observations/depth/{cam_name}"].append(
        #             depth_frames[cam_name])
        #     else:
        #         # For webcams, store a zero array to maintain consistent indexing
        #         zero_depth = np.zeros((224, 224), dtype=np.uint16)
        #         self.data_dict[f"/observations/depth/{cam_name}"].append(
        #             zero_depth)

        # print(f"total rec {time.time() - start_rec}")

    def save_data(self):
        t0 = time.time()

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        dataset_path = os.path.join(self.dataset_dir, f"episode_{timestamp}")

        num_timesteps = len(self.data_dict["/observations/qpos"])
        print(f"{num_timesteps=}")

        # intrinsics = self.cameras.get_intrinsics()
        # extrinsics = self.cameras.get_extrinsics()

        with h5py.File(dataset_path + ".hdf5", "w") as root:
            obs = root.create_group("observations")
            image = obs.create_group("images")
            depth = obs.create_group("depth")

            for cam_name in self.camera_names:
                _ = image.create_dataset(
                    cam_name,
                    (num_timesteps, 224, 224, 3),
                    dtype="uint8",
                    chunks=(1, 224, 224, 3),
                )

                if f"/observations/depth/{cam_name}" in self.data_dict:
                    _ = depth.create_dataset(
                        cam_name,
                        (num_timesteps, 224, 224),
                        dtype="uint16",
                        chunks=(1, 224, 224),
                    )

            obs.create_dataset("qpos", (num_timesteps, 7))
            obs.create_dataset("qvel", (num_timesteps, 7))
            obs.create_dataset("gpos", (num_timesteps, 1))

            obs.create_dataset("ee_pos_q", (num_timesteps, 4))
            obs.create_dataset("ee_pos_rpy", (num_timesteps, 3))
            obs.create_dataset("ee_pos_t", (num_timesteps, 3))

            obs.create_dataset("ee_twist_ang", (num_timesteps, 3))
            obs.create_dataset("ee_twist_lin", (num_timesteps, 3))

            obs.create_dataset("elbow_jnt3_pos", (num_timesteps, 1))
            obs.create_dataset("elbow_jnt4_flip", (num_timesteps, 1))

            obs.create_dataset("O_F_ext_hat_K", (num_timesteps, 6))
            obs.create_dataset("tau_J", (num_timesteps, 7))
            obs.create_dataset("dtau_J", (num_timesteps, 7))
            obs.create_dataset("tau_ext_hat_filtered", (num_timesteps, 7))

            root.create_dataset("action", (num_timesteps, 7))
            root.create_dataset("tm", (num_timesteps, 1))

            for name, array in self.data_dict.items():
                print(f"Saving: {name=}")
                root[name][...] = array

            # for cam_name in self.camera_names:
            #     print(f"Saving intrinsics for : {cam_name=}")
            #     if intrinsics[cam_name] is not None:
            #         for stream_type in ["color", "depth"]:
            #             if stream_type in intrinsics[cam_name]:
            #                 stream_intrinsics = intrinsics[cam_name][stream_type]
            #                 root.attrs[f"{cam_name}_{stream_type}_fx"] = stream_intrinsics["fx"]
            #                 root.attrs[f"{cam_name}_{stream_type}_fy"] = stream_intrinsics["fy"]
            #                 root.attrs[f"{cam_name}_{stream_type}_cx"] = stream_intrinsics["cx"]
            #                 root.attrs[f"{cam_name}_{stream_type}_cy"] = stream_intrinsics["cy"]
            #                 root.attrs[f"{cam_name}_{stream_type}_distortion"] = stream_intrinsics["distortion"]
            #     else:
            #         print(f"Value is None")

            # for cam_name in self.camera_names:
            #     print(f"Saving extrinsics for : {cam_name=}")
            #     if extrinsics[cam_name] is not None:
            #         root.attrs[f"{cam_name}_extrinsic_rotation"] = extrinsics[cam_name]["rotation"]
            #         root.attrs[f"{cam_name}_extrinsic_translation"] = extrinsics[cam_name]["translation"]
            #         root.attrs[f"{cam_name}_extrinsic_matrix"] = extrinsics[cam_name]["matrix"]
            #     else:
            #         print(f"Value is None")

        print(f"Saving: {time.time() - t0:.1f} secs\n")
